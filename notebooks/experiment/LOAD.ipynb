{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as msno\n",
    "\n",
    "join_comments = True\n",
    "join_raw_article = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load All AArticle Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\.conda\\envs\\NLP\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_comments = pd.read_csv('..//data//raw//nyt-comments-2020.csv',parse_dates=['createDate','updateDate','approveDate'])\n",
    "df_comments.sort_values(by='createDate',inplace=True,ascending=True)\n",
    "\n",
    "## Full Article Verbose / Write to file\n",
    "df_comments.to_csv('..//data//processed//df_comments.csv')\n",
    "df_comments.to_pickle('..//data//processed//df_comments.pkl')\n",
    "\n",
    "## Sample Article Verbose / Write to file\n",
    "df_sample = df_comments.sample(frac=0.05)\n",
    "df_sample.to_csv('..//data//processed//df_comments_sample.csv')\n",
    "df_sample.to_pickle('..//data//processed//df_comments_sample.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NYT Articles and Pickle\n",
    "(This is the whole list (not train and test split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Articles\n",
    "df_articles = pd.read_csv('..//data//raw//nyt-articles-2020.csv',parse_dates=['pub_date'])\n",
    "df_articles.sort_values(by='pub_date',inplace=True,ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Enhanced Articles\n",
    "\n",
    "Pull print section, print_page, lead_paragraph, and headlines to provide possible more text features that are not present in original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ..//data//raw//2020-01-articles.pickle\n",
      "Filename: ..//data//raw//2020-02-articles.pickle\n",
      "Filename: ..//data//raw//2020-03-articles.pickle\n",
      "Filename: ..//data//raw//2020-04-articles.pickle\n",
      "Filename: ..//data//raw//2020-05-articles.pickle\n",
      "Filename: ..//data//raw//2020-06-articles.pickle\n",
      "Filename: ..//data//raw//2020-07-articles.pickle\n",
      "Filename: ..//data//raw//2020-08-articles.pickle\n",
      "Filename: ..//data//raw//2020-09-articles.pickle\n",
      "Filename: ..//data//raw//2020-10-articles.pickle\n",
      "Filename: ..//data//raw//2020-11-articles.pickle\n",
      "Filename: ..//data//raw//2020-12-articles.pickle\n"
     ]
    }
   ],
   "source": [
    "# build file list matching the pickle file name pattern\n",
    "filelist = ['..//data//raw//2020-'+ str(x).zfill(2) + '-articles.pickle' for x in range(1,13)]\n",
    "\n",
    "df_articles_verbose = pd.DataFrame()\n",
    "df_temp = pd.DataFrame()\n",
    "\n",
    "# For each one of the file names\n",
    "for filename in filelist[0:13]:\n",
    "    print('Filename: ' + filename)\n",
    "    \n",
    "    # Get large articles file\n",
    "    df_json = pd.read_pickle(filename)\n",
    "    df_json = df_json[['uri','print_section','print_page','lead_paragraph','headline.main','byline.person','byline.organization','headline.sub']]\n",
    "    \n",
    "    df_temp = df_temp.append(df_json,ignore_index=True)\n",
    " \n",
    "  \n",
    "    del(df_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join enhanced article data to original article df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Articles Back\n",
    "df_articles_verbose = pd.merge(df_articles,df_temp, how='left', left_on='uniqueID',right_on='uri',suffixes=['_left','_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Article Verbose / Write to file\n",
    "df_articles_verbose.to_csv('..//data//processed//df_articles.csv')\n",
    "df_articles_verbose.to_pickle('..//data//processed//df_articles.pkl')\n",
    "\n",
    "## Sample Article Verbose / Write to file\n",
    "df_sample = df_articles_verbose.sample(frac=0.05)\n",
    "df_sample.to_csv('..//data//processed//df_articles_sample.csv')\n",
    "df_sample.to_pickle('..//data//processed//df_articles_sample.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecaab7e4f2054dc1b3b08bfc690ea1c3d11e0c83265adf695ac1706ca10c6a57"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
